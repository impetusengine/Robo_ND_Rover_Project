# Robo_ND_Rover_Project

This is the first project for the Robotics Software Engineer Nanodegree program. The goal is to create a perception pipeline as shown in perception.py and modify a decision tree as shown in decision.py so that a rover can autonomously navigate a simulation environment to collect rock samples when drive_rover.py is run. Elements of the perception pipeline include color thresholding, perspective transform, and coordinate transforms that process navigable terrain pixels, obstacle pixels, and rock sample pixels taken as an image from the front view of the rover's camera into pixels mapped onto a top-down view of the terrain. This allows the rover to locate the samples for pick-up and navigate the terrain without blindly bumping into obstacles. Further, the decision tree is improved upon to take into consideration states of the rover in which it is stuck so that it can implement actions to maneuver out of being stuck. To cover more area, the rover steers along a pixel configuration that follows the wall on its left. In a single run of the program, we have the following result: Percent mapped terrain: 99.4% Fidelity: 52.6% Rocks Located: 6 Rocks collected: 1. 
